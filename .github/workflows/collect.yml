name: Collect Cultural Data

on:
  schedule:
    - cron: '0 4 * * *'   # 06:00 Europe/Madrid
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: data-update
  cancel-in-progress: true

jobs:
  collect:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run collector and write log
        run: |
          set -e
          mkdir -p data data/sources
          echo "Run started: $(date -u +'%Y-%m-%dT%H:%M:%SZ')" > data/run.log
          python -m scrapers.collector 2>&1 | tee -a data/run.log || true
          echo "Run finished: $(date -u +'%Y-%m-%dT%H:%M:%SZ')" >> data/run.log
          echo "" >> data/run.log
          echo "=== DATA DIR LISTING ===" >> data/run.log
          ls -lah data >> data/run.log

      - name: Show run.log in job output (debug)
        run: |
          echo "----- data/run.log -----"
          cat data/run.log || true

      - name: Upload run.log as artifact (debug)
        uses: actions/upload-artifact@v4
        with:
          name: run-log
          path: data/run.log

      # âœ… Commitea TODO lo de data/ (incluye run.log) para garantizar un diff
      - name: Auto-commit data changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(data): update cultural catalog"
          file_pattern: data/**
          push_options: '--force-with-lease'
